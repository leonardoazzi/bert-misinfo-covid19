{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de dados: EDA e pré-processamento\n",
    "Giulia Chimini Stefainski, Leonardo Azzi Martins, Matheus de Moraes Costa\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo:** realizar uma análise exploratória de dados, e a partir disto definir possibilidades de pré-processamento para o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Collecting transformers==4.50.2\n",
      "  Using cached transformers-4.50.2-py3-none-any.whl (10.2 MB)\n",
      "Collecting datasets==3.5.0\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Collecting scikit-learn==1.4.2\n",
      "  Using cached scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Requirement already satisfied: evaluate==0.4.3 in ./env/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: imblearn in ./env/lib/python3.10/site-packages (0.0)\n",
      "Collecting accelerate==1.5.2\n",
      "  Using cached accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Collecting emoji==2.14.1\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Collecting torch==2.6.0\n",
      "  Using cached torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (25.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.32.3)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (6.0.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (4.67.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.5.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (3.5.0)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: aiohttp in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (3.12.6)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (20.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./env/lib/python3.10/site-packages (from seaborn==0.13.2) (3.10.3)\n",
      "Requirement already satisfied: psutil in ./env/lib/python3.10/site-packages (from accelerate==1.5.2) (7.0.0)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./env/lib/python3.10/site-packages (from torch==2.6.0) (4.13.2)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m155.9/211.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] Não há espaço disponível no dispositivo\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==1.5.3 transformers==4.50.2 datasets==3.5.0 scikit-learn==1.4.2 evaluate==0.4.3 seaborn==0.13.2 imblearn accelerate==1.5.2 emoji==2.14.1 torch==2.6.0\n",
    "#pip install torch==2.6.0+cu124 Funciona no databricks, para Torch com CUDA. Veja aí pra sua máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardoazzi/cic/25-1/pln/trabalho/bert-misinfo-covid19/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01memoji\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de dados\n",
    "Carrega o dataset a ser utilizado para fine-tuning e seleciona os atributos mais relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz o download do dataset anotado no diretório ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data/covidbr_labeled.csv'):\n",
    "  %mkdir data\n",
    "  %curl -L -o ./data/covidbr_labeled.csv https://zenodo.org/records/5193932/files/covidbr_labeled.csv\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shares</th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>source</th>\n",
       "      <th>revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>O ministro da Ciência, Tecnologia, Inovações e...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gov.br/pt-br/noticias/educacao-e-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Pesquisa com mais de 6.000 médicos em 30 paíse...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.aosfatos.org/noticias/e-falso-que-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>É com muita alegria que comunico que mais um p...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://portal.mec.gov.br/component/content/art...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>Renda Brasil unificará vários programas sociai...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://agenciabrasil.ebc.com.br/politica/noti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>O Secretário-Geral da OTAN Jens Stoltenberg ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>1</td>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>1</td>\n",
       "      <td>“OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reuters.com/article/us-health-coro...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>1</td>\n",
       "      <td>Estatísticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1</td>\n",
       "      <td>Atenção =&gt; 🇧🇷💓💓💓 *MUITO IMPORTANTE! \"Como é qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1</td>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.boatos.org/mundo/argentina-nao-exi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      shares                                               text  \\\n",
       "0         27  O ministro da Ciência, Tecnologia, Inovações e...   \n",
       "1         26  Pesquisa com mais de 6.000 médicos em 30 paíse...   \n",
       "2         25  É com muita alegria que comunico que mais um p...   \n",
       "3         25  Renda Brasil unificará vários programas sociai...   \n",
       "4         24  O Secretário-Geral da OTAN Jens Stoltenberg ta...   \n",
       "...      ...                                                ...   \n",
       "2894       1  A torcida do corona deve estar arrancando os c...   \n",
       "2895       1  “OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...   \n",
       "2896       1  Estatísticas falsas conforme depoimentos colhi...   \n",
       "2897       1  Atenção => 🇧🇷💓💓💓 *MUITO IMPORTANTE! \"Como é qu...   \n",
       "2898       1  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...   \n",
       "\n",
       "      misinformation                                             source  \\\n",
       "0                  0  https://www.gov.br/pt-br/noticias/educacao-e-p...   \n",
       "1                  1  https://www.aosfatos.org/noticias/e-falso-que-...   \n",
       "2                  0  http://portal.mec.gov.br/component/content/art...   \n",
       "3                  0  https://agenciabrasil.ebc.com.br/politica/noti...   \n",
       "4                  0                                                NaN   \n",
       "...              ...                                                ...   \n",
       "2894               0                                                NaN   \n",
       "2895               0  https://www.reuters.com/article/us-health-coro...   \n",
       "2896               1                                                NaN   \n",
       "2897               0                                                NaN   \n",
       "2898               1  https://www.boatos.org/mundo/argentina-nao-exi...   \n",
       "\n",
       "      revision  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          1.0  \n",
       "...        ...  \n",
       "2894       NaN  \n",
       "2895       1.0  \n",
       "2896       1.0  \n",
       "2897       NaN  \n",
       "2898       NaN  \n",
       "\n",
       "[2899 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset_df = pd.read_csv('./data/covidbr_labeled.csv')\n",
    "original_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O ministro da Ciência, Tecnologia, Inovações e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pesquisa com mais de 6.000 médicos em 30 paíse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>É com muita alegria que comunico que mais um p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Renda Brasil unificará vários programas sociai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Secretário-Geral da OTAN Jens Stoltenberg ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>“OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>Estatísticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>Atenção =&gt; 🇧🇷💓💓💓 *MUITO IMPORTANTE! \"Como é qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "0     O ministro da Ciência, Tecnologia, Inovações e...               0\n",
       "1     Pesquisa com mais de 6.000 médicos em 30 paíse...               1\n",
       "2     É com muita alegria que comunico que mais um p...               0\n",
       "3     Renda Brasil unificará vários programas sociai...               0\n",
       "4     O Secretário-Geral da OTAN Jens Stoltenberg ta...               0\n",
       "...                                                 ...             ...\n",
       "2894  A torcida do corona deve estar arrancando os c...               0\n",
       "2895  “OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...               0\n",
       "2896  Estatísticas falsas conforme depoimentos colhi...               1\n",
       "2897  Atenção => 🇧🇷💓💓💓 *MUITO IMPORTANTE! \"Como é qu...               0\n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...               1\n",
       "\n",
       "[2899 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = original_dataset_df[[\"text\", \"misinformation\"]]\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória de dados\n",
    "\n",
    "O objetivo é entender melhor e sumarizar as características dos dados, analisando quantidade e tipos de atributos, verificando distribuição do atributo alvo, identificando padrões e anomalias, removendo atributos que pareçam irrelevantes ou problemáticos, etc. Utilize gráficos e sumarizações estatísticas para a EDA. Verifique potenciais problemas nos dados, como por exemplo, a necessidade de normalizar os atributos, balancear classes, ou remover instâncias ou atributos por inconsistências nos dados.\n",
    "\n",
    "- P1. Qual a quantidade e tipos de atributos? Existem inconsistências?\n",
    "  - Quais são os atributos disponíveis?\n",
    "  - Existem inconsistências nos atributos? (Atributos vazios, potenciais erros, etc)\n",
    "  - Existem atributos que necessitam ser removidos ou transformados?\n",
    "- P2. Qual a distribuição do atributo alvo?\n",
    "  - Quais são as classes alvo? Qual a distribuição entre as classes? Está balanceada ou desbalanceada?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Qual a quantidade e tipos de atributos? Existem inconsistências?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Quais são os atributos disponíveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2899 entries, 0 to 2898\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   text            2898 non-null   object\n",
      " 1   misinformation  2899 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 45.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Existem inconsistências nos atributos? (Atributos vazios, potenciais erros, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Existem valores nulos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  misinformation\n",
       "847  NaN               0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove instância com texto nulo, pois é irrelevante para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              False\n",
       "misinformation    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = dataset_df.dropna()\n",
    "dataset_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Existem textos que começam com URLs e podem ser removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca por textos que começam com URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca instâncias de text onde começa com uma URL. Conforme Martins et al. 2021, estas instâncias podem dificultar a classificação, resultando em um ganho de aprox. 10% em F1-score ao remover estas instâncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/915435192.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://www.dfmobilidade.com.br/2020/06/covida...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>http://www.pf.gov.br/imprensa/noticias/2020/06...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>https://www.frontliner.com.br/a-maioria-das-pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>https://portal.fiocruz.br/coronavirus-2019-nco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>https://economia.uol.com.br/colunas/carla-arau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>https://revistaforum.com.br/noticias/china-pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>http://exame.abril.com.br/revista-exame/o-seto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "65    https://www.dfmobilidade.com.br/2020/06/covida...               0\n",
       "105   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "108   http://www.pf.gov.br/imprensa/noticias/2020/06...               0\n",
       "153   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "160   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "...                                                 ...             ...\n",
       "2868  https://www.frontliner.com.br/a-maioria-das-pe...               1\n",
       "2879  https://portal.fiocruz.br/coronavirus-2019-nco...               0\n",
       "2881  https://economia.uol.com.br/colunas/carla-arau...               0\n",
       "2886  https://revistaforum.com.br/noticias/china-pro...               0\n",
       "2891  http://exame.abril.com.br/revista-exame/o-seto...               0\n",
       "\n",
       "[604 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/915435192.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://www.dfmobilidade.com.br/2020/06/covida...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>http://www.pf.gov.br/imprensa/noticias/2020/06...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>https://www.frontliner.com.br/a-maioria-das-pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>https://portal.fiocruz.br/coronavirus-2019-nco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>https://economia.uol.com.br/colunas/carla-arau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>https://revistaforum.com.br/noticias/china-pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>http://exame.abril.com.br/revista-exame/o-seto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "65    https://www.dfmobilidade.com.br/2020/06/covida...               0\n",
       "105   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "108   http://www.pf.gov.br/imprensa/noticias/2020/06...               0\n",
       "153   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "160   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "...                                                 ...             ...\n",
       "2868  https://www.frontliner.com.br/a-maioria-das-pe...               1\n",
       "2879  https://portal.fiocruz.br/coronavirus-2019-nco...               0\n",
       "2881  https://economia.uol.com.br/colunas/carla-arau...               0\n",
       "2886  https://revistaforum.com.br/noticias/china-pro...               0\n",
       "2891  http://exame.abril.com.br/revista-exame/o-seto...               0\n",
       "\n",
       "[604 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/1956909523.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)].count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text              604\n",
       "misinformation    604\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Existe o mesmo dataset filtrado conforme Martins et al. (2021)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproduz o notebook de Martins et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/3408670061.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_df['cleanLinks'] = dataset_df['text'].apply(lambda x: re.split(r'http:\\/\\/.*', str(x))[0])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dataset_df['cleanLinks'] = dataset_df['text'].apply(lambda x: re.split(r'http:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       O ministro da Ciência, Tecnologia, Inovações e...\n",
       "1       Pesquisa com mais de 6.000 médicos em 30 paíse...\n",
       "2       É com muita alegria que comunico que mais um p...\n",
       "3       Renda Brasil unificará vários programas sociai...\n",
       "4       O Secretário-Geral da OTAN Jens Stoltenberg ta...\n",
       "                              ...                        \n",
       "2894    A torcida do corona deve estar arrancando os c...\n",
       "2895    “OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...\n",
       "2896    Estatísticas falsas conforme depoimentos colhi...\n",
       "2897    Atenção => 🇧🇷💓💓💓 *MUITO IMPORTANTE! \"Como é qu...\n",
       "2898    [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...\n",
       "Name: cleanLinks, Length: 2898, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['cleanLinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['cleanLinks'] != '' ].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Existem textos que contém URLs e podem ser removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca por textos que contém URLs e analisa a possibilidade de removê-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/2085805525.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  no_url_df = no_url_df[~no_url_df['text'].str.contains(url_pattern, regex=True, flags=re.IGNORECASE)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>cleanLinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gente, isso é EXTREMAMENTE GRAVE!!! Mandetta a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gente, isso é EXTREMAMENTE GRAVE!!! Mandetta a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Prezados amigos.. vocês sabiam que, todos os p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Prezados amigos.. vocês sabiam que, todos os p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Quando o filho de Bolsonaro culpou a China por...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quando o filho de Bolsonaro culpou a China por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...</td>\n",
       "      <td>1</td>\n",
       "      <td>URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>*Vamos ficar em casa e resguardar a nossa saúd...</td>\n",
       "      <td>1</td>\n",
       "      <td>*Vamos ficar em casa e resguardar a nossa saúd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>Mortes acumuladas por coronavírus no Brasil, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mortes acumuladas por coronavírus no Brasil, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>“OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>“OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>Estatísticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Estatísticas falsas conforme depoimentos colhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation  \\\n",
       "32    Gente, isso é EXTREMAMENTE GRAVE!!! Mandetta a...               1   \n",
       "50    Prezados amigos.. vocês sabiam que, todos os p...               1   \n",
       "54    Quando o filho de Bolsonaro culpou a China por...               1   \n",
       "56    URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...               1   \n",
       "57    *Vamos ficar em casa e resguardar a nossa saúd...               1   \n",
       "...                                                 ...             ...   \n",
       "2893  Mortes acumuladas por coronavírus no Brasil, s...               0   \n",
       "2894  A torcida do corona deve estar arrancando os c...               0   \n",
       "2895  “OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...               0   \n",
       "2896  Estatísticas falsas conforme depoimentos colhi...               1   \n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...               1   \n",
       "\n",
       "                                             cleanLinks  \n",
       "32    Gente, isso é EXTREMAMENTE GRAVE!!! Mandetta a...  \n",
       "50    Prezados amigos.. vocês sabiam que, todos os p...  \n",
       "54    Quando o filho de Bolsonaro culpou a China por...  \n",
       "56    URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...  \n",
       "57    *Vamos ficar em casa e resguardar a nossa saúd...  \n",
       "...                                                 ...  \n",
       "2893  Mortes acumuladas por coronavírus no Brasil, s...  \n",
       "2894  A torcida do corona deve estar arrancando os c...  \n",
       "2895  “OS EUA E O CORONAVÍRUS :\\n\\nAcabei de assisti...  \n",
       "2896  Estatísticas falsas conforme depoimentos colhi...  \n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...  \n",
       "\n",
       "[1330 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pattern = r'\\b(?:https?://|www\\.)\\S+\\b|\\b\\S+\\.(com|br)\\b'\n",
    "\n",
    "no_url_df = dataset_df.copy()\n",
    "no_url_df = no_url_df[~no_url_df['text'].str.contains(url_pattern, regex=True, flags=re.IGNORECASE)]\n",
    "no_url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_url_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 Existem textos com emojis que podem ser transformados ou removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca mensagens compostas por emojis\n",
    "- `emoji_count`: conta a quantidade de emojis em 'text'\n",
    "- `char_count`: conta a quantidade de caracteres em 'text'\n",
    "- `emoji_ratio`: calcula a taxa de emojis por mensagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01memoji\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_emojis\u001b[39m(text):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39mEMOJI_DATA)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "def count_emojis(text):\n",
    "    return sum(1 for char in text if char in emoji.EMOJI_DATA)\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "dataset_df['emoji_count'] = dataset_df['text'].apply(count_emojis)\n",
    "dataset_df['char_count'] = dataset_df['text'].apply(char_count)\n",
    "dataset_df['word_count'] = dataset_df['text'].apply(word_count)\n",
    "\n",
    "def emoji_ratio(text):\n",
    "    return count_emojis(text) / char_count(text) if char_count(text) > 0 else 0\n",
    "\n",
    "dataset_df['emoji_ratio'] = dataset_df['text'].apply(emoji_ratio)\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica as instâncias com maior emoji_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='emoji_ratio', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe alguma relação entre a taxa de emojis e o atributo preditivo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[dataset_df['misinformation'] == 0]['emoji_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[dataset_df['misinformation'] == 1]['emoji_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x='misinformation', y='emoji_ratio', data=dataset_df, palette=['#377eb8', '#e41a1c'])\n",
    "plt.title('Emoji Ratio vs Misinformation')\n",
    "plt.xlabel('Misinformation')\n",
    "plt.ylabel('Emoji Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica as instâncias com maior emoji_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['emoji_count'], edgecolor='black')\n",
    "plt.title('Histogram of emoji_count')\n",
    "plt.xlabel('emoji_count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(dataset_df['emoji_count'], dataset_df['char_count'], alpha=0.5)\n",
    "plt.title('Scatter Plot of Emoji Count vs Character Count')\n",
    "plt.xlabel('Emoji Count')\n",
    "plt.ylabel('Character Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='emoji_count', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não existem textos com emoji ratio maior que ~0.02. Portanto, não precisam ser tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['emoji_ratio'], edgecolor='black')\n",
    "plt.title('Histogram of moji_ratio')\n",
    "plt.xlabel('emoji_ratio')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem textos com poucas palavras significativas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='word_count', ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['word_count'], edgecolor='black')\n",
    "plt.title('Histogram of Word Count')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Qual a distribuição do atributo alvo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "series = dataset_df['misinformation'].value_counts()\n",
    "\n",
    "print(series)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.countplot(x=dataset_df['misinformation'], data = dataset_df,\n",
    "              hue='misinformation', palette=['#377eb8', '#e41a1c'],\n",
    "              order=dataset_df['misinformation'].value_counts().index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto indica que o dataset está desbalanceado, fator que pode enviesar o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "series = no_url_df['misinformation'].value_counts()\n",
    "\n",
    "print(series)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.countplot(x=no_url_df['misinformation'], data = no_url_df,\n",
    "              hue='misinformation', palette=['#377eb8', '#e41a1c'],\n",
    "              order=dataset_df['misinformation'].value_counts().index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Configurações iniciais\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Usando o dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset removendo instâncias onde o texto contém URLs em seu início"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_start_url_df = dataset_df[~dataset_df['text'].str.contains(r'^(http|www)', na=False)].reset_index(drop=True)\n",
    "no_start_url_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset removendo todas as URLs do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_url_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "O HuggingFace Trainer utiliza o rótulo labels para identificar os rótulos no treinamento. Renomeando a coluna alvo para 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.rename(columns={'misinformation': 'labels'})\n",
    "no_start_url_df = no_start_url_df.rename(columns={'misinformation': 'labels'})\n",
    "no_url_df = no_url_df.rename(columns={'misinformation': 'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o tokenizador para `bert-base-portuguese-cased` (BERTimbau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  # Or BertTokenizer\n",
    "\n",
    "hf_model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função de tokenização, que será utilizada para tokenizar cada valor de um Pandas DataFrame em forma de função de mapeamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  dataset_tk = dataset.map(tokenize_function, batched=True, remove_columns=['text']) #'__index_level_0__'\n",
    "  return dataset_tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que o dataset tem sua classe misinformation desbalanceada, utilizou-se o método de cálculo de class_weights, que atribui pesos na função loss do treinador para 'compensar' o desbalanceamento.\n",
    "\n",
    "\"If \"balanced\", class weights will be given by `n_samples / (n_classes * np.bincount(y=labels))`. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.\"\n",
    "\n",
    "Referências:\n",
    "- https://medium.com/@heyamit10/fine-tuning-bert-for-classification-a-practical-guide-b8c1c56f252c\n",
    "- https://discuss.huggingface.co/t/class-weights-for-bertforsequenceclassification/1674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_class_weights(df):\n",
    "- Cria uma instância do CrossEntropyLoss com os pesos calculados\n",
    "- Recria a classe WeightedTrainer para 'sobrescrever' a classe original no HuggingFace Trainer, utilizada a computação do loss ponderada configurada acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(df):\n",
    "  labels = df[\"labels\"]\n",
    "\n",
    "  class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "\n",
    "  class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "  print(class_weights)\n",
    "\n",
    "  loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "  class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "      \n",
    "  return WeightedTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "get_class_weights(dataset_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
