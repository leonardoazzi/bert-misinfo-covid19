{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explora√ß√£o de dados: EDA e pr√©-processamento\n",
    "Giulia Chimini Stefainski, Leonardo Azzi Martins, Matheus de Moraes Costa\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo:** realizar uma an√°lise explorat√≥ria de dados, e a partir disto definir possibilidades de pr√©-processamento para o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Collecting transformers==4.50.2\n",
      "  Using cached transformers-4.50.2-py3-none-any.whl (10.2 MB)\n",
      "Collecting datasets==3.5.0\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Collecting scikit-learn==1.4.2\n",
      "  Using cached scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Requirement already satisfied: evaluate==0.4.3 in ./env/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./env/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: imblearn in ./env/lib/python3.10/site-packages (0.0)\n",
      "Collecting accelerate==1.5.2\n",
      "  Using cached accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Collecting emoji==2.14.1\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Collecting torch==2.6.0\n",
      "  Using cached torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./env/lib/python3.10/site-packages (from pandas==1.5.3) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (25.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.32.3)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (6.0.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (4.67.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.10/site-packages (from transformers==4.50.2) (0.5.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (3.5.0)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: aiohttp in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (3.12.6)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./env/lib/python3.10/site-packages (from datasets==3.5.0) (20.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./env/lib/python3.10/site-packages (from seaborn==0.13.2) (3.10.3)\n",
      "Requirement already satisfied: psutil in ./env/lib/python3.10/site-packages (from accelerate==1.5.2) (7.0.0)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./env/lib/python3.10/site-packages (from torch==2.6.0) (4.13.2)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.9/211.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] N√£o h√° espa√ßo dispon√≠vel no dispositivo\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==1.5.3 transformers==4.50.2 datasets==3.5.0 scikit-learn==1.4.2 evaluate==0.4.3 seaborn==0.13.2 imblearn accelerate==1.5.2 emoji==2.14.1 torch==2.6.0\n",
    "#pip install torch==2.6.0+cu124 Funciona no databricks, para Torch com CUDA. Veja a√≠ pra sua m√°quina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardoazzi/cic/25-1/pln/trabalho/bert-misinfo-covid19/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01memoji\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara√ß√£o de dados\n",
    "Carrega o dataset a ser utilizado para fine-tuning e seleciona os atributos mais relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz o download do dataset anotado no diret√≥rio ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data/covidbr_labeled.csv'):\n",
    "  %mkdir data\n",
    "  %curl -L -o ./data/covidbr_labeled.csv https://zenodo.org/records/5193932/files/covidbr_labeled.csv\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shares</th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>source</th>\n",
       "      <th>revision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>O ministro da Ci√™ncia, Tecnologia, Inova√ß√µes e...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gov.br/pt-br/noticias/educacao-e-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Pesquisa com mais de 6.000 m√©dicos em 30 pa√≠se...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.aosfatos.org/noticias/e-falso-que-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>√â com muita alegria que comunico que mais um p...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://portal.mec.gov.br/component/content/art...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>Renda Brasil unificar√° v√°rios programas sociai...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://agenciabrasil.ebc.com.br/politica/noti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>O Secret√°rio-Geral da OTAN Jens Stoltenberg ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>1</td>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>1</td>\n",
       "      <td>‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reuters.com/article/us-health-coro...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>1</td>\n",
       "      <td>Estat√≠sticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1</td>\n",
       "      <td>Aten√ß√£o =&gt; üáßüá∑üíìüíìüíì *MUITO IMPORTANTE! \"Como √© qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1</td>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.boatos.org/mundo/argentina-nao-exi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      shares                                               text  \\\n",
       "0         27  O ministro da Ci√™ncia, Tecnologia, Inova√ß√µes e...   \n",
       "1         26  Pesquisa com mais de 6.000 m√©dicos em 30 pa√≠se...   \n",
       "2         25  √â com muita alegria que comunico que mais um p...   \n",
       "3         25  Renda Brasil unificar√° v√°rios programas sociai...   \n",
       "4         24  O Secret√°rio-Geral da OTAN Jens Stoltenberg ta...   \n",
       "...      ...                                                ...   \n",
       "2894       1  A torcida do corona deve estar arrancando os c...   \n",
       "2895       1  ‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...   \n",
       "2896       1  Estat√≠sticas falsas conforme depoimentos colhi...   \n",
       "2897       1  Aten√ß√£o => üáßüá∑üíìüíìüíì *MUITO IMPORTANTE! \"Como √© qu...   \n",
       "2898       1  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...   \n",
       "\n",
       "      misinformation                                             source  \\\n",
       "0                  0  https://www.gov.br/pt-br/noticias/educacao-e-p...   \n",
       "1                  1  https://www.aosfatos.org/noticias/e-falso-que-...   \n",
       "2                  0  http://portal.mec.gov.br/component/content/art...   \n",
       "3                  0  https://agenciabrasil.ebc.com.br/politica/noti...   \n",
       "4                  0                                                NaN   \n",
       "...              ...                                                ...   \n",
       "2894               0                                                NaN   \n",
       "2895               0  https://www.reuters.com/article/us-health-coro...   \n",
       "2896               1                                                NaN   \n",
       "2897               0                                                NaN   \n",
       "2898               1  https://www.boatos.org/mundo/argentina-nao-exi...   \n",
       "\n",
       "      revision  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          1.0  \n",
       "...        ...  \n",
       "2894       NaN  \n",
       "2895       1.0  \n",
       "2896       1.0  \n",
       "2897       NaN  \n",
       "2898       NaN  \n",
       "\n",
       "[2899 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset_df = pd.read_csv('./data/covidbr_labeled.csv')\n",
    "original_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O ministro da Ci√™ncia, Tecnologia, Inova√ß√µes e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pesquisa com mais de 6.000 m√©dicos em 30 pa√≠se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>√â com muita alegria que comunico que mais um p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Renda Brasil unificar√° v√°rios programas sociai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Secret√°rio-Geral da OTAN Jens Stoltenberg ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>Estat√≠sticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>Aten√ß√£o =&gt; üáßüá∑üíìüíìüíì *MUITO IMPORTANTE! \"Como √© qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "0     O ministro da Ci√™ncia, Tecnologia, Inova√ß√µes e...               0\n",
       "1     Pesquisa com mais de 6.000 m√©dicos em 30 pa√≠se...               1\n",
       "2     √â com muita alegria que comunico que mais um p...               0\n",
       "3     Renda Brasil unificar√° v√°rios programas sociai...               0\n",
       "4     O Secret√°rio-Geral da OTAN Jens Stoltenberg ta...               0\n",
       "...                                                 ...             ...\n",
       "2894  A torcida do corona deve estar arrancando os c...               0\n",
       "2895  ‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...               0\n",
       "2896  Estat√≠sticas falsas conforme depoimentos colhi...               1\n",
       "2897  Aten√ß√£o => üáßüá∑üíìüíìüíì *MUITO IMPORTANTE! \"Como √© qu...               0\n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...               1\n",
       "\n",
       "[2899 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = original_dataset_df[[\"text\", \"misinformation\"]]\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise explorat√≥ria de dados\n",
    "\n",
    "O objetivo √© entender melhor e sumarizar as caracter√≠sticas dos dados, analisando quantidade e tipos de atributos, verificando distribui√ß√£o do atributo alvo, identificando padr√µes e anomalias, removendo atributos que pare√ßam irrelevantes ou problem√°ticos, etc. Utilize gr√°ficos e sumariza√ß√µes estat√≠sticas para a EDA. Verifique potenciais problemas nos dados, como por exemplo, a necessidade de normalizar os atributos, balancear classes, ou remover inst√¢ncias ou atributos por inconsist√™ncias nos dados.\n",
    "\n",
    "- P1. Qual a quantidade e tipos de atributos? Existem inconsist√™ncias?\n",
    "  - Quais s√£o os atributos dispon√≠veis?\n",
    "  - Existem inconsist√™ncias nos atributos? (Atributos vazios, potenciais erros, etc)\n",
    "  - Existem atributos que necessitam ser removidos ou transformados?\n",
    "- P2. Qual a distribui√ß√£o do atributo alvo?\n",
    "  - Quais s√£o as classes alvo? Qual a distribui√ß√£o entre as classes? Est√° balanceada ou desbalanceada?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Qual a quantidade e tipos de atributos? Existem inconsist√™ncias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Quais s√£o os atributos dispon√≠veis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2899 entries, 0 to 2898\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   text            2898 non-null   object\n",
      " 1   misinformation  2899 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 45.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Existem inconsist√™ncias nos atributos? (Atributos vazios, potenciais erros, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Existem valores nulos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  misinformation\n",
       "847  NaN               0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove inst√¢ncia com texto nulo, pois √© irrelevante para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              False\n",
       "misinformation    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = dataset_df.dropna()\n",
    "dataset_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Existem textos que come√ßam com URLs e podem ser removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca por textos que come√ßam com URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca inst√¢ncias de text onde come√ßa com uma URL. Conforme Martins et al. 2021, estas inst√¢ncias podem dificultar a classifica√ß√£o, resultando em um ganho de aprox. 10% em F1-score ao remover estas inst√¢ncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/915435192.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://www.dfmobilidade.com.br/2020/06/covida...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>http://www.pf.gov.br/imprensa/noticias/2020/06...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>https://www.frontliner.com.br/a-maioria-das-pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>https://portal.fiocruz.br/coronavirus-2019-nco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>https://economia.uol.com.br/colunas/carla-arau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>https://revistaforum.com.br/noticias/china-pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>http://exame.abril.com.br/revista-exame/o-seto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "65    https://www.dfmobilidade.com.br/2020/06/covida...               0\n",
       "105   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "108   http://www.pf.gov.br/imprensa/noticias/2020/06...               0\n",
       "153   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "160   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "...                                                 ...             ...\n",
       "2868  https://www.frontliner.com.br/a-maioria-das-pe...               1\n",
       "2879  https://portal.fiocruz.br/coronavirus-2019-nco...               0\n",
       "2881  https://economia.uol.com.br/colunas/carla-arau...               0\n",
       "2886  https://revistaforum.com.br/noticias/china-pro...               0\n",
       "2891  http://exame.abril.com.br/revista-exame/o-seto...               0\n",
       "\n",
       "[604 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/915435192.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://www.dfmobilidade.com.br/2020/06/covida...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>http://www.pf.gov.br/imprensa/noticias/2020/06...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>https://gazetabrasil.com.br/destaques/ultimas-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>https://www.frontliner.com.br/a-maioria-das-pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>https://portal.fiocruz.br/coronavirus-2019-nco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>https://economia.uol.com.br/colunas/carla-arau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>https://revistaforum.com.br/noticias/china-pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>http://exame.abril.com.br/revista-exame/o-seto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation\n",
       "65    https://www.dfmobilidade.com.br/2020/06/covida...               0\n",
       "105   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "108   http://www.pf.gov.br/imprensa/noticias/2020/06...               0\n",
       "153   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "160   https://gazetabrasil.com.br/destaques/ultimas-...               0\n",
       "...                                                 ...             ...\n",
       "2868  https://www.frontliner.com.br/a-maioria-das-pe...               1\n",
       "2879  https://portal.fiocruz.br/coronavirus-2019-nco...               0\n",
       "2881  https://economia.uol.com.br/colunas/carla-arau...               0\n",
       "2886  https://revistaforum.com.br/noticias/china-pro...               0\n",
       "2891  http://exame.abril.com.br/revista-exame/o-seto...               0\n",
       "\n",
       "[604 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/1956909523.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)].count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text              604\n",
       "misinformation    604\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['text'].str.contains(r'^(http|www)', na=False)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Existe o mesmo dataset filtrado conforme Martins et al. (2021)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproduz o notebook de Martins et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/3408670061.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_df['cleanLinks'] = dataset_df['text'].apply(lambda x: re.split(r'http:\\/\\/.*', str(x))[0])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dataset_df['cleanLinks'] = dataset_df['text'].apply(lambda x: re.split(r'http:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       O ministro da Ci√™ncia, Tecnologia, Inova√ß√µes e...\n",
       "1       Pesquisa com mais de 6.000 m√©dicos em 30 pa√≠se...\n",
       "2       √â com muita alegria que comunico que mais um p...\n",
       "3       Renda Brasil unificar√° v√°rios programas sociai...\n",
       "4       O Secret√°rio-Geral da OTAN Jens Stoltenberg ta...\n",
       "                              ...                        \n",
       "2894    A torcida do corona deve estar arrancando os c...\n",
       "2895    ‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...\n",
       "2896    Estat√≠sticas falsas conforme depoimentos colhi...\n",
       "2897    Aten√ß√£o => üáßüá∑üíìüíìüíì *MUITO IMPORTANTE! \"Como √© qu...\n",
       "2898    [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...\n",
       "Name: cleanLinks, Length: 2898, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['cleanLinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[dataset_df['cleanLinks'] != '' ].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Existem textos que cont√©m URLs e podem ser removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca por textos que cont√©m URLs e analisa a possibilidade de remov√™-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817797/2085805525.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  no_url_df = no_url_df[~no_url_df['text'].str.contains(url_pattern, regex=True, flags=re.IGNORECASE)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>cleanLinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gente, isso √© EXTREMAMENTE GRAVE!!! Mandetta a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gente, isso √© EXTREMAMENTE GRAVE!!! Mandetta a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Prezados amigos.. voc√™s sabiam que, todos os p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Prezados amigos.. voc√™s sabiam que, todos os p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Quando o filho de Bolsonaro culpou a China por...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quando o filho de Bolsonaro culpou a China por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...</td>\n",
       "      <td>1</td>\n",
       "      <td>URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>*Vamos ficar em casa e resguardar a nossa sa√∫d...</td>\n",
       "      <td>1</td>\n",
       "      <td>*Vamos ficar em casa e resguardar a nossa sa√∫d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>Mortes acumuladas por coronav√≠rus no Brasil, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mortes acumuladas por coronav√≠rus no Brasil, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "      <td>0</td>\n",
       "      <td>A torcida do corona deve estar arrancando os c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>Estat√≠sticas falsas conforme depoimentos colhi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Estat√≠sticas falsas conforme depoimentos colhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  misinformation  \\\n",
       "32    Gente, isso √© EXTREMAMENTE GRAVE!!! Mandetta a...               1   \n",
       "50    Prezados amigos.. voc√™s sabiam que, todos os p...               1   \n",
       "54    Quando o filho de Bolsonaro culpou a China por...               1   \n",
       "56    URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...               1   \n",
       "57    *Vamos ficar em casa e resguardar a nossa sa√∫d...               1   \n",
       "...                                                 ...             ...   \n",
       "2893  Mortes acumuladas por coronav√≠rus no Brasil, s...               0   \n",
       "2894  A torcida do corona deve estar arrancando os c...               0   \n",
       "2895  ‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...               0   \n",
       "2896  Estat√≠sticas falsas conforme depoimentos colhi...               1   \n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...               1   \n",
       "\n",
       "                                             cleanLinks  \n",
       "32    Gente, isso √© EXTREMAMENTE GRAVE!!! Mandetta a...  \n",
       "50    Prezados amigos.. voc√™s sabiam que, todos os p...  \n",
       "54    Quando o filho de Bolsonaro culpou a China por...  \n",
       "56    URGENTE, SR PRESIDENTE SALVE O BRASIL E SEU PO...  \n",
       "57    *Vamos ficar em casa e resguardar a nossa sa√∫d...  \n",
       "...                                                 ...  \n",
       "2893  Mortes acumuladas por coronav√≠rus no Brasil, s...  \n",
       "2894  A torcida do corona deve estar arrancando os c...  \n",
       "2895  ‚ÄúOS EUA E O CORONAV√çRUS :\\n\\nAcabei de assisti...  \n",
       "2896  Estat√≠sticas falsas conforme depoimentos colhi...  \n",
       "2898  [2:36 PM, 11/06/2020] Wellington: ```*ALERTA A...  \n",
       "\n",
       "[1330 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pattern = r'\\b(?:https?://|www\\.)\\S+\\b|\\b\\S+\\.(com|br)\\b'\n",
    "\n",
    "no_url_df = dataset_df.copy()\n",
    "no_url_df = no_url_df[~no_url_df['text'].str.contains(url_pattern, regex=True, flags=re.IGNORECASE)]\n",
    "no_url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_url_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 Existem textos com emojis que podem ser transformados ou removidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Busca mensagens compostas por emojis\n",
    "- `emoji_count`: conta a quantidade de emojis em 'text'\n",
    "- `char_count`: conta a quantidade de caracteres em 'text'\n",
    "- `emoji_ratio`: calcula a taxa de emojis por mensagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01memoji\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_emojis\u001b[39m(text):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39mEMOJI_DATA)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "def count_emojis(text):\n",
    "    return sum(1 for char in text if char in emoji.EMOJI_DATA)\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "dataset_df['emoji_count'] = dataset_df['text'].apply(count_emojis)\n",
    "dataset_df['char_count'] = dataset_df['text'].apply(char_count)\n",
    "dataset_df['word_count'] = dataset_df['text'].apply(word_count)\n",
    "\n",
    "def emoji_ratio(text):\n",
    "    return count_emojis(text) / char_count(text) if char_count(text) > 0 else 0\n",
    "\n",
    "dataset_df['emoji_ratio'] = dataset_df['text'].apply(emoji_ratio)\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica as inst√¢ncias com maior emoji_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='emoji_ratio', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe alguma rela√ß√£o entre a taxa de emojis e o atributo preditivo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[dataset_df['misinformation'] == 0]['emoji_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[dataset_df['misinformation'] == 1]['emoji_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x='misinformation', y='emoji_ratio', data=dataset_df, palette=['#377eb8', '#e41a1c'])\n",
    "plt.title('Emoji Ratio vs Misinformation')\n",
    "plt.xlabel('Misinformation')\n",
    "plt.ylabel('Emoji Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica as inst√¢ncias com maior emoji_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['emoji_count'], edgecolor='black')\n",
    "plt.title('Histogram of emoji_count')\n",
    "plt.xlabel('emoji_count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(dataset_df['emoji_count'], dataset_df['char_count'], alpha=0.5)\n",
    "plt.title('Scatter Plot of Emoji Count vs Character Count')\n",
    "plt.xlabel('Emoji Count')\n",
    "plt.ylabel('Character Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='emoji_count', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o existem textos com emoji ratio maior que ~0.02. Portanto, n√£o precisam ser tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['emoji_ratio'], edgecolor='black')\n",
    "plt.title('Histogram of moji_ratio')\n",
    "plt.xlabel('emoji_ratio')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem textos com poucas palavras significativas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.sort_values(by='word_count', ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset_df['word_count'], edgecolor='black')\n",
    "plt.title('Histogram of Word Count')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Qual a distribui√ß√£o do atributo alvo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "series = dataset_df['misinformation'].value_counts()\n",
    "\n",
    "print(series)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.countplot(x=dataset_df['misinformation'], data = dataset_df,\n",
    "              hue='misinformation', palette=['#377eb8', '#e41a1c'],\n",
    "              order=dataset_df['misinformation'].value_counts().index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto indica que o dataset est√° desbalanceado, fator que pode enviesar o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "series = no_url_df['misinformation'].value_counts()\n",
    "\n",
    "print(series)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.countplot(x=no_url_df['misinformation'], data = no_url_df,\n",
    "              hue='misinformation', palette=['#377eb8', '#e41a1c'],\n",
    "              order=dataset_df['misinformation'].value_counts().index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Configura√ß√µes iniciais\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Usando o dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset removendo inst√¢ncias onde o texto cont√©m URLs em seu in√≠cio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_start_url_df = dataset_df[~dataset_df['text'].str.contains(r'^(http|www)', na=False)].reset_index(drop=True)\n",
    "no_start_url_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset removendo todas as URLs do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_url_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "O HuggingFace Trainer utiliza o r√≥tulo labels para identificar os r√≥tulos no treinamento. Renomeando a coluna alvo para 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.rename(columns={'misinformation': 'labels'})\n",
    "no_start_url_df = no_start_url_df.rename(columns={'misinformation': 'labels'})\n",
    "no_url_df = no_url_df.rename(columns={'misinformation': 'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o tokenizador para `bert-base-portuguese-cased` (BERTimbau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  # Or BertTokenizer\n",
    "\n",
    "hf_model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma fun√ß√£o de tokeniza√ß√£o, que ser√° utilizada para tokenizar cada valor de um Pandas DataFrame em forma de fun√ß√£o de mapeamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  dataset_tk = dataset.map(tokenize_function, batched=True, remove_columns=['text']) #'__index_level_0__'\n",
    "  return dataset_tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que o dataset tem sua classe misinformation desbalanceada, utilizou-se o m√©todo de c√°lculo de class_weights, que atribui pesos na fun√ß√£o loss do treinador para 'compensar' o desbalanceamento.\n",
    "\n",
    "\"If \"balanced\", class weights will be given by `n_samples / (n_classes * np.bincount(y=labels))`. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.\"\n",
    "\n",
    "Refer√™ncias:\n",
    "- https://medium.com/@heyamit10/fine-tuning-bert-for-classification-a-practical-guide-b8c1c56f252c\n",
    "- https://discuss.huggingface.co/t/class-weights-for-bertforsequenceclassification/1674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_class_weights(df):\n",
    "- Cria uma inst√¢ncia do CrossEntropyLoss com os pesos calculados\n",
    "- Recria a classe WeightedTrainer para 'sobrescrever' a classe original no HuggingFace Trainer, utilizada a computa√ß√£o do loss ponderada configurada acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(df):\n",
    "  labels = df[\"labels\"]\n",
    "\n",
    "  class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "\n",
    "  class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "  print(class_weights)\n",
    "\n",
    "  loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "  class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "      \n",
    "  return WeightedTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "get_class_weights(dataset_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
