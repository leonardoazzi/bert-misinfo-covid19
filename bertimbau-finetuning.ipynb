{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0C65qU6wfK7"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEIISTjXwfK9"
      },
      "outputs": [],
      "source": [
        "%pip install pandas transformers datasets torch scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ynh4tcMwfK-"
      },
      "source": [
        "# Preparação de dados\n",
        "Carrega o dataset a ser utilizado para fine-tuning e seleciona os atributos mais relevantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE0cUc2_wfK-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1pmrPkwfK_"
      },
      "source": [
        "Faz o download do dataset anotado no diretório ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXhFPYN4wfK_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('./data/covidbr_labeled.csv'):\n",
        "  !mkdir data\n",
        "  !curl -L -o ./data/covidbr_labeled.csv https://zenodo.org/records/5193932/files/covidbr_labeled.csv\n",
        "else:\n",
        "    print(\"File already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKPOuVLVwfLA"
      },
      "outputs": [],
      "source": [
        "original_dataset_df = pd.read_csv('./data/covidbr_labeled.csv')\n",
        "original_dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9osEfdnwfLA"
      },
      "outputs": [],
      "source": [
        "dataset_df = original_dataset_df[[\"text\", \"misinformation\"]]\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o75C_oFXwfLA"
      },
      "source": [
        "# Análise exploratória de dados\n",
        "\n",
        "O objetivo é entender melhor e sumarizar as características dos dados, analisando quantidade e tipos de atributos, verificando distribuição do atributo alvo, identificando padrões e anomalias, removendo atributos que pareçam irrelevantes ou problemáticos, etc. Utilize gráficos e sumarizações estatísticas para a EDA. Verifique potenciais problemas nos dados, como por exemplo, a necessidade de normalizar os atributos, balancear classes, ou remover instâncias ou atributos por inconsistências nos dados.\n",
        "\n",
        "- P1. Qual a quantidade e tipos de atributos? Existem inconsistências?\n",
        "  - Quais são os atributos disponíveis?\n",
        "  - Existem inconsistências nos atributos? (Atributos vazios, potenciais erros, etc)\n",
        "  - Existem atributos que necessitam ser removidos ou transformados?\n",
        "- P2. Qual a distribuição do atributo alvo?\n",
        "  - Quais são as classes alvo? Qual a distribuição entre as classes? Está balanceada ou desbalanceada?\n",
        "- P3. Quais os padrões e anomalias dos atributos?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P1. Qual a quantidade e tipos de atributos? Existem inconsistências?"
      ],
      "metadata": {
        "id": "9SwOgg9g0lmF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KCO1q4OwfLB"
      },
      "outputs": [],
      "source": [
        "dataset_df.info(verbose = False, memory_usage = False, show_counts = True) # mostra o tipo e a quantidade de itens não nulos de cada coluna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df.dtypes"
      ],
      "metadata": {
        "id": "HDz_81f6zPba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P2. Qual a distribuição do atributo alvo?"
      ],
      "metadata": {
        "id": "b9p7PRlU0IPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df['misinformation'].describe(include='all')"
      ],
      "metadata": {
        "id": "MS1RCHwlzkxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento"
      ],
      "metadata": {
        "id": "yjVV2NkC3sI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização"
      ],
      "metadata": {
        "id": "02jH988i4k55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o tokenizador para `bert-base-portuguese-cased` (BERTimbau)"
      ],
      "metadata": {
        "id": "Dhk4RbXcH0sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer  # Or BertTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ],
      "metadata": {
        "id": "PbEOQ9LA4tOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplica a tokenização para todas as instâncias de `text`"
      ],
      "metadata": {
        "id": "YD3RvHxcH5Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    print(examples)\n",
        "    return tokenizer(str(examples), padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "tokenized_datasets = dataset_df.apply(lambda row: tokenize_function(row[\"text\"]), axis=1)\n",
        "\n",
        "# Inspect tokenized samples\n",
        "tokenized_df = pd.DataFrame(tokenized_datasets, columns=[\"tk_text\"])\n",
        "tokenized_df"
      ],
      "metadata": {
        "id": "G4n9udCt5hI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([tokenized_df, dataset_df[\"misinformation\"]], axis=1, join=\"inner\")\n",
        "data"
      ],
      "metadata": {
        "id": "xwEuSUs6-zfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanceamento de classes"
      ],
      "metadata": {
        "id": "fizsZ4a_4jLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando o cálculo de class_weights.\n",
        "\n",
        "Fonte: https://medium.com/@heyamit10/fine-tuning-bert-for-classification-a-practical-guide-b8c1c56f252c"
      ],
      "metadata": {
        "id": "5tpWAkO9REfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "labels = data[\"misinformation\"]\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
        "print(class_weights)"
      ],
      "metadata": {
        "id": "3-6B04Qi3uqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF0zFFlUwfLB"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import datasets\n",
        "\n",
        "dataset = Dataset.from_pandas(dataset_df)\n",
        "dataset"
      ],
      "metadata": {
        "id": "zyQSQXuST392"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data = dataset.train_test_split()\n",
        "train_data = split_data[\"train\"]\n",
        "test_data = split_data[\"test\"]\n",
        "split_data"
      ],
      "metadata": {
        "id": "0-4dJB7BVJ7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n",
        "from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n",
        "from transformers import BertModel\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "print(model.config)"
      ],
      "metadata": {
        "id": "JY-ilYbTIbyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the classifier\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Keep only the classification head trainable\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
      ],
      "metadata": {
        "id": "KNoZT8mIJMlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",           # Directory for saving model checkpoints\n",
        "    #evaluation_strategy=\"epoch\",     # Evaluate at the end of each epoch\n",
        "    learning_rate=5e-5,              # Start with a small learning rate\n",
        "    per_device_train_batch_size=16,  # Batch size per GPU\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,              # Number of epochs\n",
        "    weight_decay=0.01,               # Regularization\n",
        "    save_total_limit=2,              # Limit checkpoints to save space\n",
        "    #load_best_model_at_end=True,     # Automatically load the best checkpoint\n",
        "    logging_dir=\"./logs\",            # Directory for logs\n",
        "    logging_steps=100,               # Log every 100 steps\n",
        "    fp16=True                        # Enable mixed precision for faster training\n",
        ")\n",
        "\n",
        "print(training_args)"
      ],
      "metadata": {
        "id": "_dytbZu4PfLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "# Load a metric (F1-score in this case)\n",
        "f1_metric = load(\"f1\")"
      ],
      "metadata": {
        "id": "ksex2Ai5PyaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                        # Pre-trained BERT model\n",
        "    args=training_args,                 # Training arguments\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=f1_metric     # Custom metric\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ilvMLctdQBXD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}